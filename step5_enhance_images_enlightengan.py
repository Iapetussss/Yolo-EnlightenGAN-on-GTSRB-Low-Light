"""
æ­¥éª¤ 5 (EnlightenGAN ç‰ˆ): å¢å¼ºä½å…‰ç…§å›¾åƒ
ä½¿ç”¨ EnlightenGAN æˆ–æ”¹è¿›çš„ä¼ ç»Ÿæ–¹æ³•å¢å¼ºå›¾åƒ
"""

import sys
from pathlib import Path
import shutil
import cv2
import numpy as np
from tqdm import tqdm

print("=" * 60)
print("âœ¨ æ­¥éª¤ 5: å¢å¼ºä½å…‰ç…§å›¾åƒ (EnlightenGAN ç‰ˆ)")
print("=" * 60)

# è¯»å–ä¸Šä¸€æ­¥çš„è¾“å‡ºè·¯å¾„
config_file = Path(__file__).parent / 'lowlight_dataset_path.txt'

if config_file.exists():
    with open(config_file, 'r') as f:
        input_root = Path(f.read().strip())
    print(f"\nâœ… ä½¿ç”¨ä¸Šä¸€æ­¥çš„ä½å…‰ç…§æ•°æ®é›†: {input_root}")
else:
    print("\nâš ï¸  æœªæ‰¾åˆ°ä¸Šä¸€æ­¥çš„è¾“å‡ºè·¯å¾„é…ç½®")
    print("è¯·è¾“å…¥ä½å…‰ç…§æ•°æ®é›†è·¯å¾„:")
    input_path = input("\næ•°æ®é›†è·¯å¾„: ").strip()
    
    if not input_path:
        print("âŒ å¿…é¡»æä¾›è·¯å¾„")
        sys.exit(1)
    
    input_root = Path(input_path)

if not input_root.exists():
    print(f"\nâŒ è·¯å¾„ä¸å­˜åœ¨: {input_root}")
    sys.exit(1)

# è®¾ç½®è¾“å‡ºè·¯å¾„
output_root = input_root.parent / 'enhanced_images'

print(f"\nè¾“å…¥è·¯å¾„: {input_root}")
print(f"è¾“å‡ºè·¯å¾„: {output_root}")

# æ£€æŸ¥å¢å¼ºæ–¹æ³•
print("\n" + "=" * 60)
print("é€‰æ‹©å¢å¼ºæ–¹æ³•:")
print("=" * 60)

# æ£€æŸ¥æ˜¯å¦æœ‰ EnlightenGAN æ¨¡å‹
weights_dir = Path(__file__).parent / 'weights'
onnx_model = weights_dir / "enlightengan.onnx"
pth_model = weights_dir / "enlightengan.pth"
use_traditional_flag = Path(__file__).parent / 'use_traditional_enhanced.txt'

has_onnx = onnx_model.exists()
has_pth = pth_model.exists()
use_traditional = use_traditional_flag.exists()

if has_onnx:
    print(f"âœ… æ‰¾åˆ° ONNX æ¨¡å‹: {onnx_model}")
    method_choice = "onnx"
elif has_pth:
    print(f"âœ… æ‰¾åˆ° PyTorch æ¨¡å‹: {pth_model}")
    method_choice = "pytorch"
elif use_traditional:
    print("âœ… ä½¿ç”¨æ”¹è¿›çš„ä¼ ç»Ÿæ–¹æ³•")
    method_choice = "enhanced_traditional"
else:
    print("âš ï¸  æœªæ‰¾åˆ° EnlightenGAN æ¨¡å‹")
    print("\nå¯ç”¨é€‰é¡¹:")
    print("1. ä½¿ç”¨æ”¹è¿›çš„ä¼ ç»Ÿæ–¹æ³•ï¼ˆæ¨èï¼‰")
    print("2. ä¸‹è½½ EnlightenGAN æ¨¡å‹")
    
    choice = input("\nè¯·é€‰æ‹© (1/2): ").strip()
    
    if choice == '2':
        print("\nè¯·å…ˆè¿è¡Œ: python download_enlightengan_model.py")
        sys.exit(0)
    else:
        method_choice = "enhanced_traditional"

print(f"\nä½¿ç”¨æ–¹æ³•: {method_choice}")

# å®šä¹‰å¢å¼ºå‡½æ•°
def enhanced_traditional_method(image):
    """
    æ”¹è¿›çš„ä¼ ç»Ÿæ–¹æ³•
    ç»“åˆ CLAHE, Gamma æ ¡æ­£, å’Œ Multi-Scale Retinex
    """
    # 1. è½¬æ¢åˆ° LAB è‰²å½©ç©ºé—´
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    
    # 2. åº”ç”¨ CLAHE åˆ° L é€šé“
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    l_clahe = clahe.apply(l)
    
    # 3. Gamma æ ¡æ­£
    gamma = 1.2
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 
                     for i in np.arange(0, 256)]).astype("uint8")
    l_gamma = cv2.LUT(l_clahe, table)
    
    # 4. Multi-Scale Retinex (ç®€åŒ–ç‰ˆ)
    # é«˜æ–¯æ¨¡ç³Š
    gaussian = cv2.GaussianBlur(l_gamma, (0, 0), 15)
    
    # Retinex: log(image) - log(gaussian)
    l_float = l_gamma.astype(np.float32) + 1.0
    gaussian_float = gaussian.astype(np.float32) + 1.0
    
    retinex = np.log(l_float) - np.log(gaussian_float)
    
    # å½’ä¸€åŒ–åˆ° 0-255
    retinex = cv2.normalize(retinex, None, 0, 255, cv2.NORM_MINMAX)
    l_retinex = retinex.astype(np.uint8)
    
    # 5. åˆå¹¶é€šé“
    enhanced_lab = cv2.merge([l_retinex, a, b])
    enhanced = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)
    
    # 6. é¢œè‰²å¢å¼º
    hsv = cv2.cvtColor(enhanced, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    
    # å¢åŠ é¥±å’Œåº¦
    s = cv2.add(s, 10)
    s = np.clip(s, 0, 255).astype(np.uint8)
    
    enhanced_hsv = cv2.merge([h, s, v])
    final = cv2.cvtColor(enhanced_hsv, cv2.COLOR_HSV2BGR)
    
    return final

def simple_traditional_method(image):
    """
    ç®€å•çš„ä¼ ç»Ÿæ–¹æ³•ï¼ˆåå¤‡æ–¹æ¡ˆï¼‰
    """
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    l_enhanced = clahe.apply(l)
    
    enhanced_lab = cv2.merge([l_enhanced, a, b])
    enhanced = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)
    
    gamma = 1.2
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 
                     for i in np.arange(0, 256)]).astype("uint8")
    enhanced = cv2.LUT(enhanced, table)
    
    return enhanced

def enlightengan_onnx_method(image, model_path):
    """
    ä½¿ç”¨ ONNX ç‰ˆæœ¬çš„ EnlightenGAN
    """
    try:
        import onnxruntime as ort
        
        # é¢„å¤„ç†
        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        img_normalized = (img_rgb.astype(np.float32) / 127.5) - 1.0
        img_transposed = np.transpose(img_normalized, (2, 0, 1))
        img_batch = np.expand_dims(img_transposed, axis=0)
        
        # æ¨ç†
        session = ort.InferenceSession(str(model_path))
        input_name = session.get_inputs()[0].name
        output_name = session.get_outputs()[0].name
        output = session.run([output_name], {input_name: img_batch})[0]
        
        # åå¤„ç†
        output = output.squeeze(0)
        output = np.transpose(output, (1, 2, 0))
        output = ((output + 1.0) * 127.5).clip(0, 255).astype(np.uint8)
        output_bgr = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)
        
        return output_bgr
        
    except Exception as e:
        print(f"\nâš ï¸  ONNX æ¨ç†å¤±è´¥: {e}")
        print("   å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•")
        return enhanced_traditional_method(image)

# é€‰æ‹©å¢å¼ºæ–¹æ³•
if method_choice == "onnx":
    print("\næ­£åœ¨åŠ è½½ ONNX æ¨¡å‹...")
    try:
        import onnxruntime as ort
        session = ort.InferenceSession(str(onnx_model))
        print("âœ… ONNX æ¨¡å‹åŠ è½½æˆåŠŸ")
        enhance_func = lambda img: enlightengan_onnx_method(img, onnx_model)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("å›é€€åˆ°æ”¹è¿›çš„ä¼ ç»Ÿæ–¹æ³•")
        enhance_func = enhanced_traditional_method
elif method_choice == "pytorch":
    print("\nâš ï¸  PyTorch æ¨¡å‹éœ€è¦é¢å¤–é…ç½®")
    print("æš‚æ—¶ä½¿ç”¨æ”¹è¿›çš„ä¼ ç»Ÿæ–¹æ³•")
    enhance_func = enhanced_traditional_method
else:
    enhance_func = enhanced_traditional_method

# ç¡®è®¤
print("\nâš ï¸  æ³¨æ„:")
print("   - å¢å¼ºè¿‡ç¨‹å¯èƒ½éœ€è¦ 20-40 åˆ†é’Ÿ")
print("   - éœ€è¦çº¦ 2-3 GB çš„é¢å¤–ç£ç›˜ç©ºé—´")
print("   - ä¼šä¸ºæ‰€æœ‰å›¾åƒç”Ÿæˆå¢å¼ºç‰ˆæœ¬")

response = input("\næ˜¯å¦ç»§ç»­? (è¾“å…¥ yes ç»§ç»­): ").strip().lower()

if response != 'yes':
    print("\nâŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
    sys.exit(0)

# å¼€å§‹å¢å¼º
print("\n" + "=" * 60)
print("å¼€å§‹å¢å¼ºå›¾åƒ...")
print("=" * 60)

def enhance_dataset(input_dir, output_dir, enhance_func):
    """æ‰¹é‡å¢å¼ºå›¾åƒ"""
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰å›¾åƒ
    image_files = list(input_path.glob('*.png'))
    
    if not image_files:
        print(f"   âš ï¸  æœªæ‰¾åˆ°å›¾åƒ: {input_path}")
        return 0
    
    for img_file in tqdm(image_files, desc=f"   å¢å¼º {input_path.name}"):
        try:
            # è¯»å–å›¾åƒ
            image = cv2.imread(str(img_file))
            if image is None:
                continue
            
            # å¢å¼º
            enhanced = enhance_func(image)
            
            # ä¿å­˜
            output_file = output_path / img_file.name
            cv2.imwrite(str(output_file), enhanced)
            
        except Exception as e:
            print(f"\n   âš ï¸  å¤„ç† {img_file.name} æ—¶å‡ºé”™: {e}")
            continue
    
    return len(image_files)

try:
    total_images = 0
    
    for split in ['train', 'val', 'test']:
        input_images = input_root / 'images' / split
        output_images = output_root / split
        
        if not input_images.exists():
            print(f"\nâš ï¸  è·³è¿‡ {split} (ç›®å½•ä¸å­˜åœ¨)")
            continue
        
        print(f"\nå¢å¼º {split} é›†...")
        count = enhance_dataset(input_images, output_images, enhance_func)
        total_images += count
        print(f"âœ… {split} é›†å®Œæˆ: {count} å¼ å›¾åƒ")
        
        # å¤åˆ¶æ ‡æ³¨æ–‡ä»¶
        src_labels = input_root / 'labels' / split
        dst_labels = output_root.parent / 'labels' / split
        dst_labels.mkdir(parents=True, exist_ok=True)
        
        if src_labels.exists():
            label_files = list(src_labels.glob('*.txt'))
            for label_file in label_files:
                shutil.copy(str(label_file), str(dst_labels / label_file.name))
            print(f"âœ… å¤åˆ¶ {len(label_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
    
    print("\n" + "=" * 60)
    print("âœ… å›¾åƒå¢å¼ºå®Œæˆï¼")
    print("=" * 60)
    print(f"\næ€»å…±å¢å¼º: {total_images} å¼ å›¾åƒ")
    print(f"è¾“å‡ºä½ç½®: {output_root}")
    
    # ä¿å­˜è¾“å‡ºè·¯å¾„
    output_config = Path(__file__).parent / 'enhanced_dataset_path.txt'
    with open(output_config, 'w') as f:
        f.write(str(output_root.absolute()))
    
    # æ›´æ–° YAML é…ç½®
    print("\n" + "=" * 60)
    print("æ›´æ–° YOLOv8 é…ç½®æ–‡ä»¶...")
    print("=" * 60)
    
    yaml_path = Path(__file__).parent.parent / 'traffic_signs.yaml'
    
    try:
        rel_train = output_root / 'train'
        rel_val = output_root / 'val'
        rel_test = output_root / 'test'
        
        if yaml_path.exists():
            with open(yaml_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            backup_path = yaml_path.parent / 'traffic_signs.yaml.backup'
            shutil.copy(yaml_path, backup_path)
            
            lines = content.split('\n')
            new_lines = []
            for line in lines:
                if line.startswith('train:'):
                    new_lines.append(f'train: {rel_train}')
                elif line.startswith('val:'):
                    new_lines.append(f'val: {rel_val}')
                elif line.startswith('test:'):
                    new_lines.append(f'test: {rel_test}')
                else:
                    new_lines.append(line)
            
            with open(yaml_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(new_lines))
            
            print(f"âœ… é…ç½®æ–‡ä»¶å·²æ›´æ–°: {yaml_path}")
        else:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {yaml_path}")
    
    except Exception as e:
        print(f"âš ï¸  æ›´æ–°é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ•°æ®å‡†å¤‡é˜¶æ®µå…¨éƒ¨å®Œæˆï¼")
    print("=" * 60)
    print("\nç°åœ¨ä½ å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹äº†ï¼š")
    print("   python step6_train_model.py")
    
except Exception as e:
    print("\n" + "=" * 60)
    print("âŒ å¢å¼ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:")
    print("=" * 60)
    print(str(e))
    import traceback
    traceback.print_exc()
    sys.exit(1)

