"""
è®­ç»ƒç»“æœåˆ†ææŒ‡å—
å¸®åŠ©ç†è§£å’Œåˆ†æ YOLOv8 è®­ç»ƒç»“æœ
"""

import os
from pathlib import Path
import pandas as pd

print("=" * 80)
print("ğŸ“Š YOLOv8 è®­ç»ƒç»“æœåˆ†ææŒ‡å—")
print("=" * 80)

# æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒç»“æœ
results_dir = Path('runs/train')
if not results_dir.exists():
    print("\nâŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒç»“æœç›®å½•")
    exit(1)

# æ‰¾åˆ°æœ€æ–°çš„è®­ç»ƒæ–‡ä»¶å¤¹
train_dirs = [d for d in results_dir.iterdir() if d.is_dir()]
if not train_dirs:
    print("\nâŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒç»“æœ")
    exit(1)

latest_dir = max(train_dirs, key=lambda x: x.stat().st_mtime)
print(f"\nğŸ“ åˆ†æç›®å½•: {latest_dir}")
print("=" * 80)

# è¯»å– results.csv
csv_file = latest_dir / 'results.csv'
if csv_file.exists():
    df = pd.read_csv(csv_file)
    df = df.iloc[:-1]  # ç§»é™¤æœ€åä¸€è¡Œç©ºè¡Œ
    
    print("\n" + "=" * 80)
    print("ğŸ“ˆ 1. è®­ç»ƒè¿‡ç¨‹æ¦‚è§ˆ")
    print("=" * 80)
    
    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
    final_epoch = df.iloc[-1]
    first_epoch = df.iloc[0]
    
    print(f"\næ€»è®­ç»ƒè½®æ•°: {len(df)}")
    print(f"è®­ç»ƒæ—¶é•¿: {final_epoch['time']/3600:.2f} å°æ—¶")
    
    print("\n" + "-" * 80)
    print("ğŸ¯ æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡ï¼ˆæœ€ç»ˆï¼‰:")
    print("-" * 80)
    print(f"  mAP@0.5        : {final_epoch['metrics/mAP50(B)']*100:.2f}% â­")
    print(f"  mAP@0.5:0.95   : {final_epoch['metrics/mAP50-95(B)']*100:.2f}%")
    print(f"  Precision      : {final_epoch['metrics/precision(B)']*100:.2f}%")
    print(f"  Recall         : {final_epoch['metrics/recall(B)']*100:.2f}%")
    
    # æ€§èƒ½è¯„ä»·
    map50 = final_epoch['metrics/mAP50(B)']
    print("\n" + "-" * 80)
    print("ğŸ“Š æ€§èƒ½è¯„ä»·:")
    print("-" * 80)
    if map50 > 0.95:
        print("  ğŸŒŸğŸŒŸğŸŒŸ ä¼˜ç§€ï¼æ¨¡å‹æ€§èƒ½éå¸¸å¥½ï¼")
    elif map50 > 0.85:
        print("  ğŸŒŸğŸŒŸ å¾ˆå¥½ï¼æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼")
    elif map50 > 0.70:
        print("  ğŸŒŸ ä¸é”™ï¼æ¨¡å‹åŸºæœ¬å¯ç”¨ï¼Œå¯ä»¥ç»§ç»­ä¼˜åŒ–")
    else:
        print("  âš ï¸  ä¸€èˆ¬ï¼Œå»ºè®®ç»§ç»­è®­ç»ƒæˆ–è°ƒæ•´å‚æ•°")
    
    # æ”¹è¿›å¹…åº¦
    improvement = (final_epoch['metrics/mAP50(B)'] - first_epoch['metrics/mAP50(B)']) * 100
    print(f"\n  ä»ç¬¬1è½®åˆ°ç¬¬{len(df)}è½®ï¼ŒmAP@0.5 æå‡äº†: {improvement:.2f}%")
    
    print("\n" + "-" * 80)
    print("ğŸ“‰ æŸå¤±å€¼åˆ†æï¼ˆè¶Šä½è¶Šå¥½ï¼‰:")
    print("-" * 80)
    print(f"  Box Loss   : {final_epoch['val/box_loss']:.4f}")
    print(f"  Class Loss : {final_epoch['val/cls_loss']:.4f}")
    print(f"  DFL Loss   : {final_epoch['val/dfl_loss']:.4f}")
    
    # è¿‡æ‹Ÿåˆæ£€æŸ¥
    print("\n" + "-" * 80)
    print("ğŸ” è¿‡æ‹Ÿåˆæ£€æŸ¥:")
    print("-" * 80)
    train_loss = final_epoch['train/box_loss']
    val_loss = final_epoch['val/box_loss']
    loss_gap = val_loss - train_loss
    
    if loss_gap < 0.05:
        print(f"  âœ… è‰¯å¥½ - éªŒè¯æŸå¤±å’Œè®­ç»ƒæŸå¤±æ¥è¿‘")
    elif loss_gap < 0.15:
        print(f"  âš ï¸  è½»å¾®è¿‡æ‹Ÿåˆ - å¯æ¥å—èŒƒå›´")
    else:
        print(f"  âŒ è¿‡æ‹Ÿåˆ - å»ºè®®å¢åŠ æ•°æ®å¢å¼ºæˆ–æ­£åˆ™åŒ–")
    print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f}, éªŒè¯æŸå¤±: {val_loss:.4f}")
    
else:
    print("\nâŒ æ‰¾ä¸åˆ° results.csv æ–‡ä»¶")

# åˆ†æå¯ç”¨çš„å¯è§†åŒ–æ–‡ä»¶
print("\n" + "=" * 80)
print("ğŸ–¼ï¸  2. å¯è§†åŒ–æ–‡ä»¶è¯´æ˜")
print("=" * 80)

visualizations = {
    'results.png': 'ğŸ“Š è®­ç»ƒæ›²çº¿ - æ˜¾ç¤ºæŸå¤±ã€ç²¾åº¦ã€å¬å›ç‡ç­‰éšè®­ç»ƒå˜åŒ–',
    'confusion_matrix.png': 'ğŸ¯ æ··æ·†çŸ©é˜µ - æ˜¾ç¤ºå“ªäº›ç±»åˆ«å®¹æ˜“æ··æ·†',
    'confusion_matrix_normalized.png': 'ğŸ¯ å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ - ç™¾åˆ†æ¯”å½¢å¼',
    'F1_curve.png': 'ğŸ“ˆ F1æ›²çº¿ - ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„F1åˆ†æ•°',
    'PR_curve.png': 'ğŸ“ˆ PRæ›²çº¿ - Precision-Recallå…³ç³»',
    'P_curve.png': 'ğŸ“ˆ ç²¾ç¡®ç‡æ›²çº¿',
    'R_curve.png': 'ğŸ“ˆ å¬å›ç‡æ›²çº¿',
    'BoxF1_curve.png': 'ğŸ“ˆ Box F1æ›²çº¿',
    'labels.jpg': 'ğŸ·ï¸  è®­ç»ƒæ•°æ®æ ‡ç­¾åˆ†å¸ƒ',
    'labels_correlogram.jpg': 'ğŸ·ï¸  æ ‡ç­¾ç›¸å…³æ€§å›¾',
    'train_batch0.jpg': 'ğŸ–¼ï¸  è®­ç»ƒæ‰¹æ¬¡ç¤ºä¾‹ï¼ˆå¸¦æ ‡æ³¨ï¼‰',
    'train_batch1.jpg': 'ğŸ–¼ï¸  è®­ç»ƒæ‰¹æ¬¡ç¤ºä¾‹',
    'train_batch2.jpg': 'ğŸ–¼ï¸  è®­ç»ƒæ‰¹æ¬¡ç¤ºä¾‹',
    'val_batch0_labels.jpg': 'ğŸ–¼ï¸  éªŒè¯æ‰¹æ¬¡çœŸå®æ ‡ç­¾',
    'val_batch0_pred.jpg': 'ğŸ–¼ï¸  éªŒè¯æ‰¹æ¬¡é¢„æµ‹ç»“æœ',
}

available_files = []
for filename, description in visualizations.items():
    filepath = latest_dir / filename
    if filepath.exists():
        available_files.append((filename, description))
        print(f"\nâœ… {filename}")
        print(f"   {description}")

# æ¨¡å‹æƒé‡
print("\n" + "=" * 80)
print("ğŸ’¾ 3. æ¨¡å‹æƒé‡æ–‡ä»¶")
print("=" * 80)

weights_dir = latest_dir / 'weights'
if weights_dir.exists():
    best_model = weights_dir / 'best.pt'
    last_model = weights_dir / 'last.pt'
    
    if best_model.exists():
        size_mb = best_model.stat().st_size / (1024 * 1024)
        print(f"\nâœ… best.pt - æœ€ä½³æ¨¡å‹ ({size_mb:.2f} MB)")
        print(f"   è·¯å¾„: {best_model}")
        print(f"   ğŸ“Œ è¿™æ˜¯ä½ åº”è¯¥ä½¿ç”¨çš„æ¨¡å‹ï¼")
    
    if last_model.exists():
        size_mb = last_model.stat().st_size / (1024 * 1024)
        print(f"\nâœ… last.pt - æœ€åä¸€è½®æ¨¡å‹ ({size_mb:.2f} MB)")
        print(f"   è·¯å¾„: {last_model}")

# ä½¿ç”¨å»ºè®®
print("\n" + "=" * 80)
print("ğŸ’¡ 4. å¦‚ä½•æŸ¥çœ‹å’Œä½¿ç”¨è¿™äº›ç»“æœ")
print("=" * 80)

print("""
1ï¸âƒ£  æŸ¥çœ‹è®­ç»ƒæ›²çº¿ (results.png):
   - æ‰“å¼€å›¾ç‰‡æŸ¥çœ‹å„é¡¹æŒ‡æ ‡å˜åŒ–
   - å¦‚æœæ›²çº¿å¹³ç¨³ï¼Œè¯´æ˜å·²ç»æ”¶æ•›
   - å¦‚æœè¿˜åœ¨ä¸Šå‡ï¼Œå¯ä»¥ç»§ç»­è®­ç»ƒ

2ï¸âƒ£  æŸ¥çœ‹æ··æ·†çŸ©é˜µ (confusion_matrix.png):
   - å¯¹è§’çº¿è¶Šäº®ï¼Œåˆ†ç±»è¶Šå‡†ç¡®
   - éå¯¹è§’çº¿çš„äº®ç‚¹è¡¨ç¤ºå®¹æ˜“æ··æ·†çš„ç±»åˆ«
   - å¯ä»¥é’ˆå¯¹æ€§æ”¹è¿›è¿™äº›ç±»åˆ«

3ï¸âƒ£  æŸ¥çœ‹é¢„æµ‹ç¤ºä¾‹ (val_batch*_pred.jpg):
   - ç›´è§‚çœ‹åˆ°æ¨¡å‹çš„æ£€æµ‹æ•ˆæœ
   - ç»¿è‰²æ¡† = æ­£ç¡®æ£€æµ‹
   - çº¢è‰²æ¡† = é”™è¯¯æ£€æµ‹

4ï¸âƒ£  æµ‹è¯•è‡ªå·±çš„å›¾ç‰‡:
   python step8_test_single_image.py

5ï¸âƒ£  åœ¨éªŒè¯é›†ä¸Šå®Œæ•´è¯„ä¼°:
   python step7_evaluate_model.py
""")

print("=" * 80)
print(f"ğŸ“‚ å®Œæ•´ç»“æœç›®å½•: {latest_dir.absolute()}")
print("ğŸ’¡ ç”¨æ–‡ä»¶èµ„æºç®¡ç†å™¨æ‰“å¼€æŸ¥çœ‹æ‰€æœ‰å›¾ç‰‡")
print("=" * 80)

# æä¾›å¿«æ·æ‰“å¼€å‘½ä»¤
print("\nå¿«é€Ÿæ‰“å¼€ç»“æœæ–‡ä»¶å¤¹:")
print(f"explorer \"{latest_dir.absolute()}\"")

