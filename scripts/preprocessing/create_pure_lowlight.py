"""
ç”Ÿæˆçº¯ä½å…‰ç…§æ•°æ®é›†ï¼ˆæ— ä»»ä½•å¢å¼ºï¼‰
ç”¨äº Baseline å®éªŒ
"""

import cv2
import numpy as np
from pathlib import Path
from tqdm import tqdm
import shutil
import yaml

def create_lowlight_image(image, gamma_range=(0.3, 0.7)):
    """
    ä½¿ç”¨ Gamma å˜æ¢åˆ›å»ºä½å…‰ç…§å›¾åƒ
    
    Args:
        image: è¾“å…¥å›¾åƒ
        gamma_range: Gamma å€¼èŒƒå›´
    
    Returns:
        lowlight_image: ä½å…‰ç…§å›¾åƒ
        gamma_used: ä½¿ç”¨çš„ gamma å€¼
    """
    # éšæœºé€‰æ‹© gamma å€¼
    gamma = np.random.uniform(*gamma_range)
    
    # åˆ›å»ºæŸ¥æ‰¾è¡¨
    inv_gamma = 1.0 / gamma
    table = np.array([
        ((i / 255.0) ** inv_gamma) * 255 
        for i in range(256)
    ]).astype("uint8")
    
    # åº”ç”¨ gamma å˜æ¢
    lowlight = cv2.LUT(image, table)
    
    return lowlight, gamma

def process_dataset(input_dir, output_dir, gamma_range=(0.3, 0.7)):
    """
    æ‰¹é‡å¤„ç†æ•°æ®é›†
    """
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    if not input_path.exists():
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return False
    
    # è·å–æ‰€æœ‰å›¾åƒ
    image_files = []
    for ext in ['.jpg', '.jpeg', '.png', '.ppm']:
        image_files.extend(list(input_path.rglob(f'*{ext}')))
    
    if not image_files:
        print(f"âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return False
    
    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path.mkdir(parents=True, exist_ok=True)
    
    # å¤„ç†æ¯å¼ å›¾åƒ
    success_count = 0
    gamma_values = []
    
    for img_file in tqdm(image_files, desc="ç”Ÿæˆä½å…‰ç…§å›¾åƒ"):
        try:
            # è¯»å–å›¾åƒ
            image = cv2.imread(str(img_file))
            if image is None:
                continue
            
            # ç”Ÿæˆä½å…‰ç…§ç‰ˆæœ¬
            lowlight, gamma_used = create_lowlight_image(image, gamma_range)
            gamma_values.append(gamma_used)
            
            # ä¿æŒç›¸å¯¹è·¯å¾„ç»“æ„
            rel_path = img_file.relative_to(input_path)
            out_file = output_path / rel_path
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            out_file.parent.mkdir(parents=True, exist_ok=True)
            
            # è½¬æ¢ä¸º PNG æ ¼å¼å¹¶ä¿å­˜
            out_file_png = out_file.with_suffix('.png')
            cv2.imwrite(str(out_file_png), lowlight)
            
            success_count += 1
            
        except Exception as e:
            print(f"\nå¤„ç†å¤±è´¥ {img_file}: {e}")
    
    # ç»Ÿè®¡
    avg_gamma = np.mean(gamma_values)
    print(f"\nâœ… æˆåŠŸå¤„ç†: {success_count}/{len(image_files)}")
    print(f"   å¹³å‡ Gamma: {avg_gamma:.3f}")
    print(f"   Gamma èŒƒå›´: [{min(gamma_values):.3f}, {max(gamma_values):.3f}]")
    
    return True

def copy_labels(source_label_dir, dest_label_dir):
    """
    å¤åˆ¶æ ‡ç­¾æ–‡ä»¶
    """
    source_path = Path(source_label_dir)
    dest_path = Path(dest_label_dir)
    
    if not source_path.exists():
        print(f"âš ï¸  æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {source_label_dir}")
        return False
    
    # è·å–æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶
    label_files = list(source_path.rglob('*.txt'))
    
    if not label_files:
        print("âš ï¸  æœªæ‰¾åˆ°æ ‡ç­¾æ–‡ä»¶")
        return False
    
    print(f"\nå¤åˆ¶ {len(label_files)} ä¸ªæ ‡ç­¾æ–‡ä»¶...")
    
    for label_file in tqdm(label_files, desc="å¤åˆ¶æ ‡ç­¾"):
        try:
            rel_path = label_file.relative_to(source_path)
            dest_file = dest_path / rel_path
            dest_file.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(label_file, dest_file)
        except Exception as e:
            print(f"\nå¤åˆ¶å¤±è´¥ {label_file}: {e}")
    
    print("âœ… æ ‡ç­¾å¤åˆ¶å®Œæˆ")
    return True

def create_yolo_dataset(lowlight_base, labels_source, output_dir):
    """
    åˆ›å»º YOLO æ ¼å¼æ•°æ®é›†
    """
    print("\n" + "=" * 70)
    print("åˆ›å»º YOLO æ ¼å¼æ•°æ®é›†...")
    print("=" * 70)
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºæ ‡å‡† YOLO ç»“æ„
    for split in ['train', 'val', 'test']:
        (output_path / 'images' / split).mkdir(parents=True, exist_ok=True)
        (output_path / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    # ç§»åŠ¨å›¾åƒå’Œæ ‡ç­¾
    lowlight_path = Path(lowlight_base)
    labels_path = Path(labels_source)
    
    for split in ['train', 'val', 'test']:
        # ç§»åŠ¨å›¾åƒ
        src_img_dir = lowlight_path / split
        dst_img_dir = output_path / 'images' / split
        
        if src_img_dir.exists():
            images = list(src_img_dir.glob('*.png'))
            print(f"\n{split.upper()}: ç§»åŠ¨ {len(images)} å¼ å›¾åƒ...")
            
            for img in tqdm(images, desc=f"  å›¾åƒ"):
                dst = dst_img_dir / img.name
                shutil.copy2(img, dst)
        
        # å¤åˆ¶æ ‡ç­¾
        src_label_dir = labels_path / split
        dst_label_dir = output_path / 'labels' / split
        
        if src_label_dir.exists():
            labels = list(src_label_dir.glob('*.txt'))
            print(f"   å¤åˆ¶ {len(labels)} ä¸ªæ ‡ç­¾...")
            
            for label in tqdm(labels, desc=f"  æ ‡ç­¾"):
                dst = dst_label_dir / label.name
                shutil.copy2(label, dst)
    
    print("\nâœ… YOLO æ•°æ®é›†åˆ›å»ºå®Œæˆ")
    print(f"   ä½ç½®: {output_path}")
    
    return output_path

def create_config(dataset_path, config_path='configs/exp1_baseline.yaml'):
    """
    åˆ›å»º YAML é…ç½®æ–‡ä»¶
    """
    config = {
        'path': str(Path(dataset_path).absolute()),
        'train': 'images/train',
        'val': 'images/val',
        'test': 'images/test',
        'nc': 43,
        'names': [
            "speed_20", "speed_30", "speed_50", "speed_60", "speed_70", "speed_80",
            "speed_80_end", "speed_100", "speed_120", "no_overtaking", "no_overtaking_trucks",
            "priority_at_next_intersection", "priority_road", "give_way", "stop", "no_entry",
            "no_entry_trucks", "no_entry_one_way", "general_caution", "dangerous_curve_left",
            "dangerous_curve_right", "double_curve", "bumpy_road", "slippery_road",
            "road_narrows_right", "road_works", "traffic_signals", "pedestrians",
            "children_crossing", "bicycles_crossing", "ice_or_snow", "wild_animals_crossing",
            "end_of_all_speed_and_overtaking_limits", "turn_right_ahead", "turn_left_ahead",
            "ahead_only", "go_straight_or_right", "go_straight_or_left", "keep_right",
            "keep_left", "roundabout_mandatory", "end_of_no_overtaking",
            "end_of_no_overtaking_trucks"
        ]
    }
    
    config_file = Path(config_path)
    config_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(config_file, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    print(f"\nâœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_file}")
    
    return config_file

def main():
    """ä¸»å‡½æ•°"""
    
    print("\n" + "=" * 70)
    print("  ç”Ÿæˆçº¯ä½å…‰ç…§æ•°æ®é›†ï¼ˆBaseline å®éªŒç”¨ï¼‰".center(70))
    print("=" * 70)
    
    print("\nè¯´æ˜:")
    print("  â€¢ ä½¿ç”¨ Gamma å˜æ¢ç”Ÿæˆä½å…‰ç…§å›¾åƒ")
    print("  â€¢ Gamma èŒƒå›´: [0.3, 0.7]")
    print("  â€¢ ä¸è¿›è¡Œä»»ä½•å¢å¼ºå¤„ç†")
    print("  â€¢ ç”¨äºå»ºç«‹æ€§èƒ½åŸºçº¿")
    
    # æ£€æŸ¥æºæ•°æ®
    print("\n" + "=" * 70)
    print("æ£€æŸ¥æºæ•°æ®...")
    print("=" * 70)
    
    # å¯»æ‰¾åŸå§‹æ•°æ®
    source_options = [
        ('yolo_dataset/images', 'yolo_dataset/labels'),
        ('traffic_sign_data/original/images', 'traffic_sign_data/labels'),
    ]
    
    source_img_dir = None
    source_label_dir = None
    
    for img_dir, label_dir in source_options:
        if Path(img_dir).exists() and Path(label_dir).exists():
            source_img_dir = img_dir
            source_label_dir = label_dir
            break
    
    if not source_img_dir:
        print("âŒ æœªæ‰¾åˆ°æºæ•°æ®")
        print("\næç¤º: å°†ä½¿ç”¨ yolo_dataset ä½œä¸ºæºï¼ˆè™½ç„¶å®ƒå·²å¢å¼ºè¿‡ï¼‰")
        print("     ä½å…‰ç…§åŒ–åä»å¯ç”¨äºå¯¹æ¯”")
        source_img_dir = 'yolo_dataset/images'
        source_label_dir = 'yolo_dataset/labels'
    
    print(f"âœ… æºå›¾åƒ: {source_img_dir}")
    print(f"âœ… æºæ ‡ç­¾: {source_label_dir}")
    
    # ç¡®è®¤å¼€å§‹
    print("\n" + "=" * 70)
    print("âš ï¸  æ³¨æ„äº‹é¡¹:")
    print("=" * 70)
    print("  â€¢ å¤„ç†æ—¶é—´: çº¦ 30-60 åˆ†é’Ÿ")
    print("  â€¢ éœ€è¦ç£ç›˜ç©ºé—´: çº¦ 5GB")
    print("  â€¢ è¾“å‡ºç›®å½•: data/baseline_lowlight_dataset/")
    
    response = input("\næ˜¯å¦å¼€å§‹ç”Ÿæˆï¼Ÿ(y/N): ").strip().lower()
    if response != 'y':
        print("å·²å–æ¶ˆ")
        return
    
    # å¼€å§‹å¤„ç†
    temp_lowlight = Path('data/temp_lowlight')
    
    # æ­¥éª¤ 1: ç”Ÿæˆä½å…‰ç…§å›¾åƒ
    print("\n" + "=" * 70)
    print("æ­¥éª¤ 1/3: ç”Ÿæˆä½å…‰ç…§å›¾åƒ...")
    print("=" * 70)
    
    for split in ['train', 'val', 'test']:
        split_dir = Path(source_img_dir) / split
        if split_dir.exists():
            print(f"\nå¤„ç† {split.upper()} é›†...")
            process_dataset(
                split_dir,
                temp_lowlight / split,
                gamma_range=(0.3, 0.7)
            )
    
    # æ­¥éª¤ 2: åˆ›å»º YOLO æ•°æ®é›†
    print("\n" + "=" * 70)
    print("æ­¥éª¤ 2/3: ç»„ç»‡ä¸º YOLO æ ¼å¼...")
    print("=" * 70)
    
    final_dataset = create_yolo_dataset(
        temp_lowlight,
        source_label_dir,
        'data/baseline_lowlight_dataset'
    )
    
    # æ­¥éª¤ 3: åˆ›å»ºé…ç½®æ–‡ä»¶
    print("\n" + "=" * 70)
    print("æ­¥éª¤ 3/3: åˆ›å»ºé…ç½®æ–‡ä»¶...")
    print("=" * 70)
    
    config_file = create_config(final_dataset)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    print("\næ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
    shutil.rmtree(temp_lowlight, ignore_errors=True)
    
    # å®Œæˆ
    print("\n" + "=" * 70)
    print("  âœ… çº¯ä½å…‰ç…§æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼".center(70))
    print("=" * 70)
    
    print(f"\næ•°æ®é›†ä½ç½®: {final_dataset}")
    print(f"é…ç½®æ–‡ä»¶: {config_file}")
    
    # ç»Ÿè®¡
    for split in ['train', 'val', 'test']:
        img_dir = final_dataset / 'images' / split
        if img_dir.exists():
            count = len(list(img_dir.glob('*.png')))
            print(f"  {split.upper():<6}: {count:>6} å¼ ")
    
    print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print("   è¿è¡Œ Baseline å®éªŒ:")
    print(f"   python scripts/training/train_baseline.py")
    
    print("\n" + "=" * 70 + "\n")

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nå·²å–æ¶ˆ")
    except Exception as e:
        print(f"\nâŒ å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

