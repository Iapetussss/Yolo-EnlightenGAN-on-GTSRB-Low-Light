"""
å¿«é€Ÿæµ‹è¯•å•å¼ å›¾åƒ
è‡ªåŠ¨ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹
"""

from pathlib import Path
import random
import sys

def find_best_model():
    """æ‰¾åˆ°æœ€å¥½çš„è®­ç»ƒæ¨¡å‹"""
    models = list(Path('runs/train').glob('*/weights/best.pt'))
    
    if not models:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
        print("è¯·å…ˆå®Œæˆè®­ç»ƒ: python step6_train_model.py")
        return None
    
    # ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹
    latest_model = max(models, key=lambda p: p.stat().st_mtime)
    return latest_model

def find_test_image():
    """æ‰¾ä¸€å¼ æµ‹è¯•å›¾åƒ"""
    possible_dirs = [
        Path('traffic_sign_data/enhanced_images/test'),
        Path('yolo_dataset/images/test'),
        Path('yolo_dataset/images/val'),
    ]
    
    for img_dir in possible_dirs:
        if img_dir.exists():
            images = list(img_dir.glob('*.png')) + list(img_dir.glob('*.jpg'))
            if images:
                return random.choice(images)
    
    return None

def main():
    print("\n" + "=" * 70)
    print("  å¿«é€Ÿå›¾åƒæµ‹è¯•".center(70))
    print("=" * 70)
    
    # 1. æ‰¾æ¨¡å‹
    print("\nğŸ” å¯»æ‰¾è®­ç»ƒå¥½çš„æ¨¡å‹...")
    model_path = find_best_model()
    
    if not model_path:
        sys.exit(1)
    
    print(f"âœ… æ‰¾åˆ°æ¨¡å‹: {model_path}")
    print(f"   è®­ç»ƒå®éªŒ: {model_path.parent.parent.name}")
    
    # 2. æ‰¾æµ‹è¯•å›¾åƒ
    print("\nğŸ” é€‰æ‹©æµ‹è¯•å›¾åƒ...")
    test_image = find_test_image()
    
    if not test_image:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒ")
        sys.exit(1)
    
    print(f"âœ… æµ‹è¯•å›¾åƒ: {test_image}")
    
    # 3. åŠ è½½æ¨¡å‹å’Œé¢„æµ‹
    print("\nğŸš€ å¼€å§‹æµ‹è¯•...")
    print("-" * 70)
    
    from ultralytics import YOLO
    import cv2
    import matplotlib.pyplot as plt
    
    # åŠ è½½æ¨¡å‹
    model = YOLO(str(model_path))
    
    # é¢„æµ‹
    results = model.predict(
        source=str(test_image),
        conf=0.25,
        save=False,
        verbose=False
    )
    
    # è·å–ç»“æœ
    result = results[0]
    
    print(f"\nğŸ“Š æ£€æµ‹ç»“æœ:")
    print(f"   æ£€æµ‹åˆ° {len(result.boxes)} ä¸ªç›®æ ‡")
    
    if len(result.boxes) > 0:
        print("\nè¯¦ç»†ä¿¡æ¯:")
        for i, box in enumerate(result.boxes):
            cls = int(box.cls[0])
            conf = float(box.conf[0])
            # è·å–ç±»åˆ«åç§°
            class_name = result.names[cls]
            print(f"   {i+1}. {class_name}: {conf:.2%} ç½®ä¿¡åº¦")
    else:
        print("   âš ï¸  æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
    
    # 4. å¯è§†åŒ–
    print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–...")
    
    # è¯»å–åŸå›¾
    img = cv2.imread(str(test_image))
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # è·å–æ ‡æ³¨åçš„å›¾åƒ
    annotated = result.plot()
    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    axes[0].imshow(img_rgb)
    axes[0].set_title('Original Image', fontsize=14, fontweight='bold')
    axes[0].axis('off')
    
    axes[1].imshow(annotated_rgb)
    axes[1].set_title(f'Detection Result ({len(result.boxes)} objects)', fontsize=14, fontweight='bold')
    axes[1].axis('off')
    
    plt.tight_layout()
    
    # ä¿å­˜
    output_path = 'quick_test_result.png'
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ… ç»“æœå·²ä¿å­˜: {output_path}")
    
    # æ˜¾ç¤º
    try:
        plt.show()
    except:
        pass
    
    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 70)
    
    print("\nğŸ’¡ æƒ³æµ‹è¯•æ›´å¤šå›¾åƒï¼Ÿå†æ¬¡è¿è¡Œ:")
    print("   python quick_test_image.py")

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nå·²å–æ¶ˆ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

